{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11851119,"sourceType":"datasetVersion","datasetId":7446689},{"sourceId":11892992,"sourceType":"datasetVersion","datasetId":7475436}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:40:36.755558Z","iopub.execute_input":"2025-05-20T14:40:36.755834Z","iopub.status.idle":"2025-05-20T14:40:45.280950Z","shell.execute_reply.started":"2025-05-20T14:40:36.755811Z","shell.execute_reply":"2025-05-20T14:40:45.280374Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wandb.login(key='13b86763ab8ddf529c91c7dce385c6cb04b5253e')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:47:28.002652Z","iopub.execute_input":"2025-05-20T14:47:28.003189Z","iopub.status.idle":"2025-05-20T14:47:34.530243Z","shell.execute_reply.started":"2025-05-20T14:47:28.003161Z","shell.execute_reply":"2025-05-20T14:47:34.529634Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m015\u001b[0m (\u001b[33miitm-ma23m015\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.train.tsv\"\ndev_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.dev.tsv\"\ntest_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.test.tsv\"\n\ntrain_df = pd.read_csv(train_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\ndev_df = pd.read_csv(dev_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\ntest_df = pd.read_csv(test_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\n\ntrain_df = train_df.dropna(subset=['source','target'])\ndev_df = dev_df.dropna(subset=['source','target'])\ntest_df = test_df.dropna(subset=['source','target'])\n\ntrain_pairs = [(str(s), str(t)) for s,t in zip(train_df.source, train_df.target)]\ndev_pairs = [(str(s), str(t)) for s,t in zip(dev_df.source, dev_df.target)]\ntest_pairs = [(str(s), str(t)) for s,t in zip(test_df.source, test_df.target)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:47:34.531296Z","iopub.execute_input":"2025-05-20T14:47:34.531652Z","iopub.status.idle":"2025-05-20T14:47:34.679297Z","shell.execute_reply.started":"2025-05-20T14:47:34.531634Z","shell.execute_reply":"2025-05-20T14:47:34.678498Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nclass CharVocab:\n    def __init__(self, sequences):\n        self.char2idx = {'<pad>':0, '<sos>':1, '<eos>':2, '<unk>':3}\n        self.idx2char = ['<pad>', '<sos>', '<eos>', '<unk>']\n        chars = set(''.join(sequences))\n        for ch in sorted(chars):\n            self.char2idx[ch] = len(self.idx2char)\n            self.idx2char.append(ch)\n    def encode(self, text):\n        return [self.char2idx.get(c, self.char2idx['<unk>']) for c in text]\n    def decode(self, indices):\n        result = []\n        for idx in indices:\n            if idx == self.char2idx['<eos>']:\n                break\n            if idx not in (self.char2idx['<pad>'], self.char2idx['<sos>']):\n                result.append(self.idx2char[idx])\n        return ''.join(result)\n    def __len__(self):\n        return len(self.idx2char)\n\n# Create vocabularies\nsrc_vocab = CharVocab([s for s,_ in train_pairs])\ntgt_vocab = CharVocab([t for _,t in train_pairs])\n\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, src_vocab, tgt_vocab):\n        self.pairs = pairs\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n    def __len__(self):\n        return len(self.pairs)\n    def __getitem__(self, idx):\n        src, tgt = self.pairs[idx]\n        src_enc = torch.tensor(self.src_vocab.encode(src), dtype=torch.long)\n        tgt_enc = torch.tensor([self.tgt_vocab.char2idx['<sos>']] + self.tgt_vocab.encode(tgt) + [self.tgt_vocab.char2idx['<eos>']], dtype=torch.long)\n        return src_enc, tgt_enc\n\ndef collate_fn(batch):\n    src_seqs, tgt_seqs = zip(*batch)\n    src_padded = pad_sequence(src_seqs, batch_first=True, padding_value=src_vocab.char2idx['<pad>'])\n    tgt_padded = pad_sequence(tgt_seqs, batch_first=True, padding_value=tgt_vocab.char2idx['<pad>'])\n    return src_padded, tgt_padded\n\n# Create datasets\ntrain_ds = TransliterationDataset(train_pairs, src_vocab, tgt_vocab)\ndev_ds = TransliterationDataset(dev_pairs, src_vocab, tgt_vocab)\ntest_ds = TransliterationDataset(test_pairs, src_vocab, tgt_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:47:34.680096Z","iopub.execute_input":"2025-05-20T14:47:34.680294Z","iopub.status.idle":"2025-05-20T14:47:34.731323Z","shell.execute_reply.started":"2025-05-20T14:47:34.680274Z","shell.execute_reply":"2025-05-20T14:47:34.730621Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, cell_type, pad_idx, bidirectional=False):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        self.n_layers = n_layers\n        self.hid_dim = hid_dim\n        self.bidirectional = bidirectional\n        self.n_directions = 2 if bidirectional else 1\n        \n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[self.cell_type]\n        self.rnn = rnn_cls(\n            emb_dim, \n            hid_dim, \n            n_layers, \n            batch_first=True, \n            dropout=dropout if n_layers > 1 else 0,\n            bidirectional=bidirectional\n        )\n        \n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, hidden = self.rnn(embedded)\n        \n        # Process hidden state based on RNN type\n        if self.cell_type == 'LSTM':\n            \n            h_n, c_n = hidden          \n            if self.bidirectional:\n \n                h_n = h_n.view(self.n_layers, self.n_directions, -1, self.hid_dim)\n                h_n = h_n.sum(dim=1)  # Sum the bidirectional outputs\n                \n                c_n = c_n.view(self.n_layers, self.n_directions, -1, self.hid_dim)\n                c_n = c_n.sum(dim=1)  # Sum the bidirectional outputs\n                \n            return (h_n, c_n)\n        else:\n            if self.bidirectional:\n                hidden = hidden.view(self.n_layers, self.n_directions, -1, self.hid_dim)\n                hidden = hidden.sum(dim=1)  \n                \n            return hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:47:34.732591Z","iopub.execute_input":"2025-05-20T14:47:34.732797Z","iopub.status.idle":"2025-05-20T14:47:34.752124Z","shell.execute_reply.started":"2025-05-20T14:47:34.732781Z","shell.execute_reply":"2025-05-20T14:47:34.751395Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, cell_type, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        self.n_layers = n_layers\n        self.hid_dim = hid_dim\n        \n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[self.cell_type]\n        self.rnn = rnn_cls(\n            emb_dim, \n            hid_dim, \n            n_layers, \n            batch_first=True, \n            dropout=dropout if n_layers > 1 else 0\n        )\n        self.fc_out = nn.Linear(hid_dim, output_dim)\n        \n    def forward(self, input, hidden):\n        input = input.unsqueeze(1)\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.rnn(embedded, hidden)\n        prediction = self.fc_out(output.squeeze(1))\n        return prediction, hidden\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, emb_dim, hid_dim, enc_layers, dec_layers, dropout, cell_type, device, bidirectional=False):\n        super().__init__()\n        self.device = device\n        self.encoder = Encoder(\n            src_vocab_size, \n            emb_dim, \n            hid_dim, \n            enc_layers, \n            dropout, \n            cell_type, \n            pad_idx=src_vocab.char2idx['<pad>'],\n            bidirectional=bidirectional\n        )\n        self.decoder = Decoder(\n            tgt_vocab_size, \n            emb_dim, \n            hid_dim, \n            dec_layers, \n            dropout, \n            cell_type, \n            pad_idx=tgt_vocab.char2idx['<pad>']\n        )\n        self.tgt_vocab_size = tgt_vocab_size\n        self.cell_type = cell_type.upper()\n    \n    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        max_len = tgt.size(1)\n        outputs = torch.zeros(batch_size, max_len, self.tgt_vocab_size).to(self.device)\n\n        encoder_hidden = self.encoder(src)\n        decoder_hidden = encoder_hidden\n        \n        input = tgt[:, 0]\n\n        for t in range(1, max_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            outputs[:, t] = output\n            teacher_force = np.random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = tgt[:, t] if teacher_force else top1\n        return outputs\n\n    def beam_search(self, src, beam_width=3, max_len=50):\n        batch_size = src.size(0)\n        hidden = self.encoder(src)\n        decoder_hidden = hidden\n        input = torch.tensor([tgt_vocab.char2idx['<sos>']] * batch_size).to(self.device)\n\n        decoded_words = [[] for _ in range(batch_size)]\n        for _ in range(max_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            top1 = output.argmax(1)\n            input = top1\n            for i in range(batch_size):\n                decoded_words[i].append(top1[i].item())\n        decoded_sentences = [tgt_vocab.decode(seq) for seq in decoded_words]\n        return decoded_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T14:47:39.092200Z","iopub.execute_input":"2025-05-20T14:47:39.092493Z","iopub.status.idle":"2025-05-20T14:47:39.101995Z","shell.execute_reply.started":"2025-05-20T14:47:39.092472Z","shell.execute_reply":"2025-05-20T14:47:39.101121Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for src, tgt in dataloader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, tgt)\n        output_dim = output.shape[-1]\n        output = output[:,1:,:].reshape(-1, output_dim)\n        tgt = tgt[:,1:].reshape(-1)\n        loss = criterion(output, tgt)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)\n\ndef word_accuracy(model, loader, src_vocab, tgt_vocab, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            batch_size = src.size(0)\n            outputs = model(src, tgt, teacher_forcing_ratio=0)\n            # Get predicted indices: max over vocab dimension\n            pred_indices = outputs.argmax(dim=2)  # batch x seq_len\n            \n            for i in range(batch_size):\n                pred_word = tgt_vocab.decode(pred_indices[i].cpu().numpy())\n                true_word = tgt_vocab.decode(tgt[i].cpu().numpy())\n                if pred_word == true_word:\n                    correct += 1\n                total += 1\n    return correct / total\n\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for src, tgt in dataloader:\n            src, tgt = src.to(device), tgt.to(device)\n            output = model(src, tgt, teacher_forcing_ratio=0)\n            output_dim = output.shape[-1]\n            output = output[:,1:,:].reshape(-1, output_dim)\n            tgt = tgt[:,1:].reshape(-1)\n            loss = criterion(output, tgt)\n            epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nsweep_config = {\n    'method': 'bayes',\n    'name': 'sweep - no attention',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'validation_accuracy'\n    },\n    'parameters': {\n        'input_embedding_size': {\n            'values': [64, 128]  # 16,32,64,\n        },\n        'enc_layers': {\n            'values': [1, 2, 3]\n        },\n        'dec_layers': {\n            'values': [1, 2, 3]\n        },\n        'emb_hidden_size': {\n            'values': [64, 128, 256]\n        },\n        'hidden_size': {\n            'values': [64, 128, 256]\n        },\n        'cell_type': {\n            'values': ['LSTM', 'RNN', 'GRU']\n        },\n        'bidirectional': {\n            'values': [True,False]\n        },\n        'dropout': {\n            'values': [0.1, 0.2, 0.3]\n        },\n        'beam_size': {\n            'values': [1, 3, 5]\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='MA23M015_DL_Assignment3')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:01:11.809946Z","iopub.execute_input":"2025-05-20T15:01:11.810652Z","iopub.status.idle":"2025-05-20T15:01:12.237692Z","shell.execute_reply.started":"2025-05-20T15:01:11.810626Z","shell.execute_reply":"2025-05-20T15:01:12.236986Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: hrvozery\nSweep URL: https://wandb.ai/iitm-ma23m015/MA23M015_DL_Assignment3/sweeps/hrvozery\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def main():\n    with wandb.init() as run:\n        config = wandb.config\n        \n        BATCH_SIZE = 64\n        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n        dev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n        \n        wandb.run.name = f'cell-{config.cell_type}_emb_hid_sz-{config.emb_hidden_size}_hid_size-{config.hidden_size}_inp_embed-{config.input_embedding_size}_enc-{config.enc_layers}_dec-{config.dec_layers}_dropout-{config.dropout}'\n        \n        DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        model = Seq2Seq(\n            src_vocab_size=len(src_vocab),\n            tgt_vocab_size=len(tgt_vocab),\n            emb_dim=config.emb_hidden_size,\n            hid_dim=config.hidden_size,\n            enc_layers=config.enc_layers,\n            dec_layers=config.enc_layers,  # note fix here, before you used enc_layers twice\n            dropout=config.dropout,\n            cell_type=config.cell_type,\n            device=DEVICE,\n            bidirectional=config.bidirectional\n        ).to(DEVICE)\n        \n        optimizer = torch.optim.Adam(model.parameters())\n        criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.char2idx['<pad>'])\n        \n        EPOCHS = 2\n        for epoch in range(1, EPOCHS + 1):\n            train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n            train_acc = word_accuracy(model, train_loader, src_vocab, tgt_vocab, DEVICE)\n            \n            val_loss = evaluate(model, dev_loader, criterion, DEVICE)\n            val_acc = word_accuracy(model, dev_loader, src_vocab, tgt_vocab, DEVICE)\n            \n            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f} Train Acc={train_acc:.4f} \"\n                  f\"Val Loss={val_loss:.4f} Val Acc={val_acc:.4f}\")\n            \n            wandb.log({\n                'Epoch': epoch,\n                'train_loss': train_loss,\n                'Train_accuracy': train_acc * 100,\n                'validation_loss': val_loss,\n                'validation_accuracy': val_acc * 100\n            })\nwandb.agent(sweep_id, function=main, count=1)\nwandb.finish()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\n\n\nEMB_DIM = 256           \nHID_DIM = 256            \nENC_LAYERS = 3           \nDEC_LAYERS = 3          \nDROPOUT = 0.3            \nCELL_TYPE = 'LSTM'       \nBATCH_SIZE = 64\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\ntrain_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.train.tsv\"\ndev_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.dev.tsv\"\ntest_path = \"/kaggle/input/tamil-translit/ta.translit.sampled.test.tsv\"\n\ntrain_df = pd.read_csv(train_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\ndev_df = pd.read_csv(dev_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\ntest_df = pd.read_csv(test_path, sep=\"\\t\", header=None, names=[\"target\",\"source\",\"freq\"])\n\ntrain_df = train_df.dropna(subset=['source','target'])\ndev_df = dev_df.dropna(subset=['source','target'])\ntest_df = test_df.dropna(subset=['source','target'])\n\ntrain_pairs = [(str(s), str(t)) for s,t in zip(train_df.source, train_df.target)]\ndev_pairs = [(str(s), str(t)) for s,t in zip(dev_df.source, dev_df.target)]\ntest_pairs = [(str(s), str(t)) for s,t in zip(test_df.source, test_df.target)]\n\n\nclass CharVocab:\n    def __init__(self, sequences):\n        self.char2idx = {'<pad>':0, '<sos>':1, '<eos>':2, '<unk>':3}\n        self.idx2char = ['<pad>', '<sos>', '<eos>', '<unk>']\n        chars = set(''.join(sequences))\n        for ch in sorted(chars):\n            self.char2idx[ch] = len(self.idx2char)\n            self.idx2char.append(ch)\n    def encode(self, text):\n        return [self.char2idx.get(c, self.char2idx['<unk>']) for c in text]\n    def decode(self, indices):\n        result = []\n        for idx in indices:\n            if idx == self.char2idx['<eos>']:\n                break\n            if idx not in (self.char2idx['<pad>'], self.char2idx['<sos>']):\n                result.append(self.idx2char[idx])\n        return ''.join(result)\n    def __len__(self):\n        return len(self.idx2char)\n\nsrc_vocab = CharVocab([s for s,_ in train_pairs])\ntgt_vocab = CharVocab([t for _,t in train_pairs])\n\n# --- Dataset ---\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, src_vocab, tgt_vocab):\n        self.pairs = pairs\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n    def __len__(self):\n        return len(self.pairs)\n    def __getitem__(self, idx):\n        src, tgt = self.pairs[idx]\n        src_enc = torch.tensor(self.src_vocab.encode(src), dtype=torch.long)\n        tgt_enc = torch.tensor([self.tgt_vocab.char2idx['<sos>']] + self.tgt_vocab.encode(tgt) + [self.tgt_vocab.char2idx['<eos>']], dtype=torch.long)\n        return src_enc, tgt_enc\n\ndef collate_fn(batch):\n    src_seqs, tgt_seqs = zip(*batch)\n    src_padded = pad_sequence(src_seqs, batch_first=True, padding_value=src_vocab.char2idx['<pad>'])\n    tgt_padded = pad_sequence(tgt_seqs, batch_first=True, padding_value=tgt_vocab.char2idx['<pad>'])\n    return src_padded, tgt_padded\n\ntrain_ds = TransliterationDataset(train_pairs, src_vocab, tgt_vocab)\ndev_ds = TransliterationDataset(dev_pairs, src_vocab, tgt_vocab)\ntest_ds = TransliterationDataset(test_pairs, src_vocab, tgt_vocab)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\n\n\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, cell_type, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[self.cell_type]\n        self.rnn = rnn_cls(emb_dim, hid_dim, n_layers, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, hidden = self.rnn(embedded)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, cell_type, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[self.cell_type]\n        self.rnn = rnn_cls(emb_dim, hid_dim, n_layers, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n        self.fc_out = nn.Linear(hid_dim, output_dim)\n    def forward(self, input, hidden):\n        input = input.unsqueeze(1)\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.rnn(embedded, hidden)\n        prediction = self.fc_out(output.squeeze(1))\n        return prediction, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, emb_dim, hid_dim, enc_layers, dec_layers, dropout, cell_type, device):\n        super().__init__()\n        self.device = device\n        self.encoder = Encoder(src_vocab_size, emb_dim, hid_dim, enc_layers, dropout, cell_type, pad_idx=src_vocab.char2idx['<pad>'])\n        self.decoder = Decoder(tgt_vocab_size, emb_dim, hid_dim, dec_layers, dropout, cell_type, pad_idx=tgt_vocab.char2idx['<pad>'])\n        self.tgt_vocab_size = tgt_vocab_size\n        self.cell_type = cell_type.upper()\n    \n    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        max_len = tgt.size(1)\n        outputs = torch.zeros(batch_size, max_len, self.tgt_vocab_size).to(self.device)\n\n        hidden = self.encoder(src)\n        decoder_hidden = hidden\n        \n        input = tgt[:, 0]\n\n        for t in range(1, max_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            outputs[:, t] = output\n            teacher_force = np.random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = tgt[:, t] if teacher_force else top1\n        return outputs\n\n    def beam_search(self, src, beam_width=3, max_len=50):\n        # Simple greedy decoder as a placeholder for beam search\n        batch_size = src.size(0)\n        hidden = self.encoder(src)\n        decoder_hidden = hidden\n        input = torch.tensor([tgt_vocab.char2idx['<sos>']] * batch_size).to(self.device)\n\n        decoded_words = [[] for _ in range(batch_size)]\n        for _ in range(max_len):\n            output, decoder_hidden = self.decoder(input, decoder_hidden)\n            top1 = output.argmax(1)\n            input = top1\n            for i in range(batch_size):\n                decoded_words[i].append(top1[i].item())\n        decoded_sentences = [tgt_vocab.decode(seq) for seq in decoded_words]\n        return decoded_sentences\n\n\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for src, tgt in dataloader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, tgt)\n        output_dim = output.shape[-1]\n        output = output[:,1:,:].reshape(-1, output_dim)\n        tgt = tgt[:,1:].reshape(-1)\n        loss = criterion(output, tgt)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)\n\ndef word_accuracy(model, loader, src_vocab, tgt_vocab, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            batch_size = src.size(0)\n            outputs = model(src, tgt, teacher_forcing_ratio=0)\n            # Get predicted indices: max over vocab dimension\n            pred_indices = outputs.argmax(dim=2)  # batch x seq_len\n            \n            for i in range(batch_size):\n                pred_word = tgt_vocab.decode(pred_indices[i].cpu().numpy())\n                true_word = tgt_vocab.decode(tgt[i].cpu().numpy())\n                if pred_word == true_word:\n                    correct += 1\n                total += 1\n    return correct / total\n\n\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for src, tgt in dataloader:\n            src, tgt = src.to(device), tgt.to(device)\n            output = model(src, tgt, teacher_forcing_ratio=0)\n            output_dim = output.shape[-1]\n            output = output[:,1:,:].reshape(-1, output_dim)\n            tgt = tgt[:,1:].reshape(-1)\n            loss = criterion(output, tgt)\n            epoch_loss += loss.item()\n    return epoch_loss / len(dataloader)\n\n\nmodel = Seq2Seq(len(src_vocab), len(tgt_vocab), EMB_DIM, HID_DIM, ENC_LAYERS, DEC_LAYERS, DROPOUT, CELL_TYPE, DEVICE).to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.char2idx['<pad>'])\n\n\nEPOCHS = 5\nfor epoch in range(1, EPOCHS+1):\n    train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n    train_acc = word_accuracy(model, train_loader, src_vocab, tgt_vocab,DEVICE)  # train accuracy\n    \n    val_loss = evaluate(model, dev_loader, criterion, DEVICE)\n    val_acc = word_accuracy(model, dev_loader, src_vocab, tgt_vocab,DEVICE)      # val accuracy\n    \n    print(f\"Epoch {epoch}: Train Loss={train_loss:.4f} Train Acc={train_acc:.4f} \"\n          f\"Val Loss={val_loss:.4f} Val Acc={val_acc:.4f}\")\n\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm  \n\ndef collect_predictions(model, dataloader, src_vocab, tgt_vocab, device):\n    model.eval()\n    out = []\n\n    with torch.no_grad():\n        for src, tgt in tqdm(dataloader, desc=\"Predicting\"):\n            src, tgt = src.to(device), tgt.to(device)\n            outputs = model(src, tgt, teacher_forcing_ratio=0)        # (batch, seq, vocab)\n            pred_ids = outputs.argmax(dim=2).cpu().numpy()            # np array\n\n            for i in range(src.size(0)):\n                translit = src_vocab.decode(src[i].cpu().numpy())\n                true_w   = tgt_vocab.decode(tgt[i].cpu().numpy())\n                pred_w   = tgt_vocab.decode(pred_ids[i])\n                out.append((translit, true_w, pred_w))\n\n    return out\n\n\npred_tuples = collect_predictions(model, test_loader, src_vocab, tgt_vocab, DEVICE)\n\n\ndf = pd.DataFrame(pred_tuples,\n                  columns=[\"Transliteration\", \"trueword\", \"predicted_word\"])\n\nout_file = Path(\"test_predictions.csv\")\ndf.to_csv(out_file, index=False, encoding=\"utf-8-sig\")\nprint(f\"\\n Saved full results to {out_file.resolve()}\")\n\n\ntest_acc = (df[\"trueword\"] == df[\"predicted_word\"]).mean()\nprint(f\"\\nWord‑level **test accuracy**: {test_acc:.4f}\")\n\n\nprint(\"\\n── Last 100 predictions ──\")\nprint(df.tail(100).to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:03:44.922213Z","iopub.execute_input":"2025-05-20T16:03:44.922969Z","iopub.status.idle":"2025-05-20T16:09:21.932143Z","shell.execute_reply.started":"2025-05-20T16:03:44.922945Z","shell.execute_reply":"2025-05-20T16:09:21.931470Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss=1.8904 Train Acc=0.2765 Val Loss=1.1854 Val Acc=0.2587\nEpoch 2: Train Loss=0.6511 Train Acc=0.5545 Val Loss=0.8765 Val Acc=0.4615\nEpoch 3: Train Loss=0.4434 Train Acc=0.6654 Val Loss=0.7768 Val Acc=0.5093\nEpoch 4: Train Loss=0.3491 Train Acc=0.7275 Val Loss=0.7613 Val Acc=0.5382\nEpoch 5: Train Loss=0.2930 Train Acc=0.7724 Val Loss=0.7430 Val Acc=0.5406\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 108/108 [00:01<00:00, 70.81it/s]","output_type":"stream"},{"name":"stdout","text":"\n Saved full results to /kaggle/working/test_predictions.csv\n\nWord‑level **test accuracy**: 0.5347\n\n── Last 100 predictions ──\n  Transliteration       trueword predicted_word\n     vaelaikkaana      வேலைக்கான      வேலைக்கான\n       vaelaikkup     வேலைக்குப்     வேலைக்குப்\n       vaelaikkum     வேலைக்கும்     வேலைக்கும்\n         vaelaich         வேலைச்         வேலைச்\n       paarppavar         வேலைப்     பார்ப்பவர்\n        paarththu         வேலைப்       பார்த்து\n        parppavar         வேலைப்        பற்பவர்\n      vaelaiyaaga        வேலையாக        வேலையாக\n      vaelaiyaaka        வேலையாக        வேலையாக\n      vealaiyaaka        வேலையாக        வேலையாக\n        vaelaiyin       வேலையின்       வேலையின்\n        vealaiyin       வேலையின்       வேலையின்\n        vaelaiyil       வேலையில்       வேலையில்\n        vealaiyil       வேலையில்       வேலையில்\n     vaelaiyaiyum     வேலையையும்     வேலையையும்\n     vealaiyaiyum     வேலையையும்     வேலையையும்\n              vai             வை             வை\n      vaiguntarin    வைகுண்டரின்    வைக்ணுறனின்\n      vaikundarin    வைகுண்டரின்    வைக்குன்றன்\n        vaiguntar      வைகுண்டர்      வைகுண்டர்\n        vaikundar      வைகுண்டர்      வைகுண்டர்\n vaiththiyanaatha     வைத்தியநாத     வைத்தியானத\nvaiththiyanaathan   வைத்தியநாதன்  வைத்தியானதான்\n         vaibavam         வைபவம்         வைபவம்\n         vaipavam         வைபவம்            வைப\n            volga         வோல்கா          வொல்க\n           volgaa         வோல்கா         வொல்கா\n           voolga         வோல்கா          வூழ்க\n           voolka         வோல்கா          வூழ்க\n          vooulga         வோல்கா          வோல்க\n           voulga         வோல்கா         வோல்கா\n          vouulga         வோல்கா         வோல்கா\n            wolga         வோல்கா         வோல்கா\n           wolgaa         வோல்கா         வோல்கா\n           woolga         வோல்கா          வூழ்க\n          woolgaa         வோல்கா         வூல்கா\n           woulga         வோல்கா         வோல்கா\n            shaam           ஷாம்           ஷாம்\n             sham           ஷாம்           ஷாம்\n          shaavai           ஷாவை           சாவை\n          shahvai           ஷாவை         ஷாவாய்\n           shavai           ஷாவை           சாவை\n          escotch       ஸ்காட்ச்        எஸ்டோஸ்\n           scotch       ஸ்காட்ச்       ஸ்காட்ஸ்\n          skaatch       ஸ்காட்ச்       ஸ்காட்ஸ்\n            skoch       ஸ்காட்ச்         ஸ்கோஸ்\n           skotch       ஸ்காட்ச்       ஸ்காட்ஸ்\n            sqoch       ஸ்காட்ச்         ஸ்காஸ்\n           sqotch       ஸ்காட்ச்       ஸ்காட்ஸ்\n   scotlaanththin ஸ்காட்லாந்தின் ஸ்கோட்லாந்தின்\n       scotlandin ஸ்காட்லாந்தின் ஸ்காட்லாந்தின்\n    skaatlaandhin ஸ்காட்லாந்தின் ஸ்காட்லாந்தின்\n        sthaabaga         ஸ்தாபக        ஸ்தாபாக\n        sthaapaga         ஸ்தாபக        ஸ்தாபாக\n   shreenivaachan    ஸ்ரீநிவாசன்    ஸ்ரீனிவாசன்\n     sreenivaasan    ஸ்ரீநிவாசன்    ஸ்ரீனிவாசன்\n     srinivaachan    ஸ்ரீநிவாசன்    ஸ்ரீனிவாசன்\n      srinivaasan    ஸ்ரீநிவாசன்    ஸ்ரீனிவாசன்\n       srinivasan    ஸ்ரீநிவாசன்    ஸ்ரீனிவாசன்\nshreerangkaththil ஸ்ரீரங்கத்தில் ஸ்ரீரங்கத்தில்\n  sreerankaththil ஸ்ரீரங்கத்தில் ஸ்ரீரங்கத்தில்\n   srirangaththil ஸ்ரீரங்கத்தில் ஸ்ரீரங்கத்தில்\n  sriranggaththil ஸ்ரீரங்கத்தில் ஸ்ரீரங்கத்தில்\n  srirangkaththil ஸ்ரீரங்கத்தில் ஸ்ரீரங்கத்தில்\n         hangaran     ஹங்கேரியன்        ஹங்கரன்\n        hangarian     ஹங்கேரியன்       ஹங்கரின்\n      hankeeriyan     ஹங்கேரியன்     ஹங்கேரியன்\n         hungaran     ஹங்கேரியன்       ஹுங்கரன்\n        hungarian     ஹங்கேரியன்      ஹுங்கரின்\n       huungarian     ஹங்கேரியன்      ஹுங்கரின்\n     hanggaeriyil    ஹங்கேரியில்    ஹங்கேரியில்\n      hankeariyil    ஹங்கேரியில்    ஹங்கேரியில்\n      hungaeriyil    ஹங்கேரியில்   ஹுங்கேறியில்\n        hungaryil    ஹங்கேரியில்    ஹுங்கரியில்\n       hungaryyil    ஹங்கேரியில்    ஹுங்கரியில்\n          harijan         ஹரிஜன்         ஹரிசன்\n          paattar           ஹாரி        பாட்டர்\n          paatter           ஹாரி        பாட்டர்\n           pattar           ஹாரி         பட்டர்\n           potter           ஹாரி         பட்டர்\n           haaris         ஹாரிஸ்         ஹாரிஸ்\n           hairis         ஹாரிஸ்         ஹெர்ஸ்\n          hairiss         ஹாரிஸ்         ஹெர்ஸ்\n            hares         ஹாரிஸ்          ஹரீஸ்\n            haris         ஹாரிஸ்         ஹெர்ஸ்\n            hariz         ஹாரிஸ்          ஹரிஸ்\n           harres         ஹாரிஸ்           ஹரர்\n           harrij         ஹாரிஸ்          ஹரிஜ்\n           harris         ஹாரிஸ்         ஹெர்ஸ்\n          harriss         ஹாரிஸ்         ஹிர்ஸ்\n           harriz         ஹாரிஸ்          ஹரில்\n           heriss         ஹாரிஸ்         ஹெர்ஸ்\n             hael           ஹெல்           ஹெல்\n              hel           ஹெல்           ஹெல்\n             hell           ஹெல்           ஹெல்\n          haidroa         ஹைட்ரோ         ஹைட்ரா\n          haitrao         ஹைட்ரோ         ஹைத்ரோ\n            hydro         ஹைட்ரோ         ஹித்ரோ\n          haithar          ஹைதர்         ஹத்தர்\n            hyder          ஹைதர்          ஹிடர்\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}